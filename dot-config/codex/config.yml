# ~/.codex/config.yaml
model: o4-mini-2025-04-16                                   # ğŸŸ¢ Pick your flavour
api_key_env: OPENAI_API_KEY                                 # ğŸŸ¡ Make sure youâ€™ve exported this
base_url: https://api.openai.com/v1/chat/completions
timeout: 30                                                 # ğŸŸ£ Seconds before we give up on OpenAIâ€™s brain

llms:
  openai:
    provider: openai                                        # ğŸŸ¢ â€œWho ya gonna call?â€ â†’ OpenAI
    model: o4-mini-2025-04-16                           # ğŸ”µ Pick your flavour
    api_key_env: OPENAI_API_KEY                             # ğŸŸ¡ Make sure youâ€™ve exported this
    base_url: https://api.openai.com/v1/chat/completions    # ğŸ”´ Vertex AI endpoint for GPT-4
    timeout: 30                                             # ğŸŸ£ Seconds before we give up on OpenAIâ€™s brain

  google-gemini:
    provider: google                                        # ğŸŸ¢ â€œWho ya gonna call?â€ â†’ Google
    model: gemini-2.5-flash-preview-04-17                   # ğŸ”µ Pick your flavour
    api_key_env: GOOGLE_AI_API_KEY                          # ğŸŸ¡ Make sure youâ€™ve exported this
    base_url: https://generativelanguage.googleapis.com/v1/models
                                                            # ğŸ”´ Vertex AI endpoint for Gemini
    timeout: 30                                             # ğŸŸ£ Seconds before we give up on Googleâ€™s brain

  anthropic-claude:
    provider: anthropic                                     # ğŸŸ¢ â€œWho ya gonna call?â€ â†’ Anthropic
    model: claude-v3.5.                                     # ğŸ”µ Pick your flavour
    api_key_env: ANTHROPIC_API_KEY                          # ğŸŸ¡ Make sure youâ€™ve exported this
    base_url: https://api.anthropic.com/v1/complete
                                                            # ğŸ”´ Vertex AI endpoint for Claude
    timeout: 30                                             # ğŸŸ£ Seconds before we give up on Anthropicâ€™s brain

  openrouter:
    provider: openrouter                                    # ğŸŸ¢ â€œWho ya gonna call?â€ â†’ OpenRouter
    model: openrouter-v1-alpha-7b-chat-001                  # ğŸ”µ Pick your flavour
    api_key_env: OPENROUTER_API_KEY                         # ğŸŸ¡ Make sure youâ€™ve exported this
    base_url: https://openrouter.ai/api/v1
                                                            # ğŸ”´ Vertex AI endpoint for OpenRouter
    timeout: 30                                             # ğŸŸ£ Seconds before we give up on OpenRouterâ€™s brain

  lmstudio:
    provider: lmstudio                                      # ğŸŸ¢ â€œWho ya gonna call?â€ â†’ LM Studio
    model: lmstudio-vicuna-7b-v1.3                          # ğŸ”µ Pick your flavour
    api_key_env: LM_STUDIO_API_KEY                          # ğŸŸ¡ Make sure youâ€™ve exported this
    base_url: https://lmstudio.ai/api/v1
                                                            # ğŸ”´ Vertex AI endpoint for LM Studio
    timeout: 30                                             # ğŸŸ£ Seconds before we give up on LM Studioâ€™s brain

fullAutoErrorMode: ask-user # or ignore-and-continue
mode: auto-edit

# Enables or disables the plugin update message when joining the server.
update_notify: true

# This option defines the time (in seconds) to automatically save
# player data.
player_data_save: 300

# Format to display dates when a discovery was found.
discoveries_date_format: "/yyyy-MM-dd"

# Format of the %progress_bar% variable on the lore of category items.
progress_bar_placeholder:
  filled_symbol: "&a|"
  empty_symbol: "&c|"
  amount: 20

# MySQL support credentials.
mysql_database:
  enabled: false
  host: localhost
  port: 3306
  username: root
  password: root
  database: database

# PostgreSQL support credentials.
postgresql_database:
  enabled: true
  host: localhost
  port: 5432
  username: postgres
  password:
  database: codex

# Don't modify.
config_version: 2
