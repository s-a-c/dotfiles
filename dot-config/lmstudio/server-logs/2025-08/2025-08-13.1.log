[2025-08-13 00:02:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:04:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:05:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:08:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:11:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:13:19][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:14:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:17:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:20:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:23:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:26:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:29:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:31:05][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:31:05][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 00:31:05][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 00:31:32][INFO] Finished streaming response
[2025-08-13 00:31:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:31:42][INFO][LM STUDIO SERVER] Running chat completion on conversation with 3 messages.
[2025-08-13 00:31:42][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 00:32:21][INFO] Finished streaming response
[2025-08-13 00:32:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:32:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:32:36][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 00:32:36][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 00:33:21][INFO] Finished streaming response
[2025-08-13 00:33:26][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:33:26][INFO][LM STUDIO SERVER] Running chat completion on conversation with 3 messages.
[2025-08-13 00:33:26][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 00:33:56][INFO] Finished streaming response
[2025-08-13 00:35:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:36:54][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:36:54][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 00:36:54][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 00:37:53][INFO] Finished streaming response
[2025-08-13 00:38:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:41:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:44:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:46:02][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:46:02][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 00:46:02][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 00:46:19][INFO] Finished streaming response
[2025-08-13 00:47:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:50:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:53:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:56:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 00:59:27][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:02:28][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:05:26][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:05:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:05:56][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:06:03][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:08:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:08:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:11:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:14:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:17:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:20:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:23:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:26:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:29:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:29:38][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:29:59][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:32:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:35:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:38:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:41:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:44:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:46:19][INFO] Unloading model qwen/qwen3-32b due to TTL expiration.
[2025-08-13 01:47:31][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:50:31][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:53:31][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:55:57][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:55:57][INFO][JIT] Requested model (qwen/qwen3-32b) is not loaded. Loading "qwen/qwen3-32b" now...
[2025-08-13 01:55:57][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loading",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:55:57][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loading",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:55:57][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loading",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:55:57][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 01:55:57][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 01:55:57][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 01:55:57][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 01:55:57][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 01:55:57][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 01:56:07][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 01:56:07][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 01:56:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:56:33][INFO] Finished streaming response
[2025-08-13 01:57:14][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:57:14][INFO][LM STUDIO SERVER] Running chat completion on conversation with 3 messages.
[2025-08-13 01:57:14][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 01:57:38][INFO] Finished streaming response
[2025-08-13 01:58:40][INFO] Finished streaming response
[2025-08-13 01:59:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 01:59:49][INFO] Finished streaming response
[2025-08-13 02:01:02][INFO] Finished streaming response
[2025-08-13 02:02:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:05:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:06:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:06:36][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:06:36][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:06:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:06:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:06:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:06:36][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:06:36][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:06:36][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:06:36][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:06:36][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:06:36][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:07:00][INFO] Finished streaming response
[2025-08-13 02:07:35][INFO] Finished streaming response
[2025-08-13 02:08:25][INFO] Finished streaming response
[2025-08-13 02:08:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:09:22][INFO] Finished streaming response
[2025-08-13 02:11:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:13:32][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:13:32][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:13:32][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:13:32][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:13:32][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:13:32][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:14:19][INFO] Finished streaming response
[2025-08-13 02:14:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:15:47][INFO] Finished streaming response
[2025-08-13 02:17:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:20:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:23:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:26:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:29:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:32:33][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:33:18][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:35:37][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:38:37][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:41:37][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:41:51][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:42:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:42:36][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:42:36][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:42:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:42:36][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:42:36][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:43:29][INFO] Finished streaming response
[2025-08-13 02:44:37][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:44:38][INFO] Finished streaming response
[2025-08-13 02:44:41][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:44:41][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:44:41][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:44:41][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:44:41][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 02:44:41][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 02:45:01][INFO] Finished streaming response
[2025-08-13 02:45:46][INFO] Finished streaming response
[2025-08-13 02:47:37][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:50:37][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:53:37][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:56:17][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:56:24][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:56:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:56:37][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:56:57][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:57:01][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:57:10][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 02:57:15][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:00:10][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:03:11][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:06:11][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:09:11][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:12:11][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:15:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:18:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:21:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:24:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:27:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:30:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:33:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:36:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:39:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:42:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:45:23][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:45:46][INFO] Unloading model qwen/qwen3-32b due to TTL expiration.
[2025-08-13 03:48:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:51:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:54:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 03:57:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:00:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:03:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:06:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:09:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:12:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:15:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:18:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:21:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:24:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:27:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:30:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:33:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:36:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:39:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:42:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:45:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:48:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:51:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:54:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 04:57:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:00:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:03:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:06:24][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:09:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:12:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:15:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:18:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:21:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:24:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:27:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:30:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:33:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:36:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:39:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:42:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:45:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:48:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:51:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:54:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 05:57:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:00:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:03:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:06:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:09:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:12:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:15:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:18:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:21:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:24:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:27:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:30:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:33:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:36:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:39:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:42:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:45:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:48:29][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:51:31][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:54:31][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 06:57:31][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:00:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:03:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:06:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:09:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:12:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:15:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:18:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:21:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:24:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:27:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:30:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:33:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:36:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:39:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:42:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:45:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:48:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:51:35][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:54:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:57:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:58:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 07:59:50][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:00:34][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:00:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:02:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:02:55][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:03:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:06:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:08:24][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:09:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:12:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:15:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:18:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:21:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:24:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:27:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:30:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:33:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:36:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:39:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:42:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:45:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:48:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:51:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:54:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 08:57:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:00:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:00:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:01:28][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:03:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:04:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:06:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:09:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:12:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:15:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:18:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:21:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:24:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:27:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:30:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:33:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:36:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:39:50][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:42:49][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:45:49][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:48:49][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:51:51][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:54:52][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 09:57:53][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:00:53][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:03:53][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:06:53][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:09:53][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:12:54][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:15:55][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:18:55][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:21:55][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:24:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:27:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:30:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:33:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:36:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:39:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:42:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:45:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:48:56][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:51:57][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:54:57][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 10:57:59][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:01:00][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:04:01][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:07:01][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:10:01][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:13:03][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:16:03][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:19:03][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:22:03][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:25:03][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:28:03][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:31:03][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:34:04][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:37:06][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:40:16][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:43:18][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:46:20][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:49:20][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:52:20][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:55:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 11:58:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:01:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:04:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:07:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:10:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:13:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:16:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:19:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:22:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:25:21][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:28:23][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:31:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:34:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:37:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:40:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:43:28][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:46:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:49:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:50:20][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:51:02][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:52:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:55:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 12:58:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:01:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:04:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:07:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:10:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:13:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:16:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:19:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:22:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:25:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:28:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:31:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:34:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:35:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:37:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:40:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:43:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:46:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:49:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:52:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:53:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:55:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 13:58:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:01:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:04:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:07:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:10:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:12:58][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:13:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:13:54][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:15:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:16:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:19:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:22:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:25:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:28:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:31:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:34:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:37:30][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:40:34][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:43:36][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:46:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:49:45][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:52:45][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:55:45][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 14:58:45][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:01:45][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:04:45][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:07:47][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:10:49][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:13:50][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:16:50][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:19:50][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:22:50][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:25:50][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:28:50][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:31:52][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:34:52][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:37:52][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:40:54][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:43:58][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:46:59][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:50:01][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:53:01][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:56:02][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 15:59:03][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:02:04][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:05:06][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:08:07][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:11:09][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:14:10][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:16:06][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:17:00][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:17:11][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:20:11][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:23:11][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:24:45][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:26:11][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:29:11][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:30:02][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:32:11][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:34:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:34:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:35:33][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:37:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:39:49][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:41][INFO][JIT] Requested model (qwen/qwen3-32b) is not loaded. Loading "qwen/qwen3-32b" now...
[2025-08-13 16:40:48][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loading",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:40:48][INFO][LM STUDIO SERVER] Running chat completion on conversation with 3 messages.
[2025-08-13 16:40:48][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:40:56][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 16:40:56][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:41:28][INFO] Finished streaming response
[2025-08-13 16:42:32][INFO] Finished streaming response
[2025-08-13 16:43:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:45:05][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:46:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:49:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:49:50][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:49:50][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:49:50][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:49:50][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:49:50][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:49:50][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 16:49:50][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:50:19][INFO] Finished streaming response
[2025-08-13 16:51:02][INFO] Finished streaming response
[2025-08-13 16:51:09][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:51:09][INFO][LM STUDIO SERVER] Running chat completion on conversation with 3 messages.
[2025-08-13 16:51:09][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 16:51:46][INFO] Finished streaming response
[2025-08-13 16:52:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:53:12][INFO] Finished streaming response
[2025-08-13 16:54:22][INFO] Finished streaming response
[2025-08-13 16:55:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 16:55:38][INFO] Finished streaming response
[2025-08-13 16:56:51][INFO] Finished streaming response
[2025-08-13 16:58:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:01:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:04:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:07:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:07:33][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:09:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:10:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:10:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 17:10:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:10:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:10:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:10:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:10:25][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 17:10:25][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 17:10:50][INFO] Finished streaming response
[2025-08-13 17:11:30][INFO] Finished streaming response
[2025-08-13 17:12:30][INFO] Finished streaming response
[2025-08-13 17:13:13][INFO] Finished streaming response
[2025-08-13 17:13:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:14:31][INFO] Finished streaming response
[2025-08-13 17:15:33][INFO] Finished streaming response
[2025-08-13 17:16:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:19:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:19:50][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:22:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:25:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:28:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:31:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:34:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:37:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:40:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:43:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:46:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:49:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:52:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:55:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 17:58:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:01:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:04:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:07:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:10:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:13:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:15:33][INFO] Unloading model qwen/qwen3-32b due to TTL expiration.
[2025-08-13 18:16:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:19:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:22:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:25:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:28:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:31:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:34:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:37:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:40:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:43:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:46:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:49:22][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:52:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:55:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 18:58:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:01:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:04:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:07:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:10:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:13:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:16:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:19:25][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:22:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:25:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:28:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:31:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:34:26][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:37:27][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:40:28][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:43:28][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:46:28][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:49:28][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:52:31][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:55:32][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 19:58:34][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:01:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:04:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:07:38][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:10:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:13:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:16:39][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:19:40][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:22:40][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:25:41][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:28:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:31:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:34:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:37:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:40:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:43:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:46:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:48:17][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:49:42][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:51:04][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:51:04][INFO][JIT] Requested model (qwen/qwen3-32b) is not loaded. Loading "qwen/qwen3-32b" now...
[2025-08-13 20:51:16][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 20:51:16][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 20:51:39][INFO] Finished streaming response
[2025-08-13 20:51:49][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:51:49][INFO][LM STUDIO SERVER] Running chat completion on conversation with 3 messages.
[2025-08-13 20:51:49][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 20:52:19][INFO] Finished streaming response
[2025-08-13 20:52:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:53:54][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:53:54][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 20:53:54][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 20:54:26][INFO] Finished streaming response
[2025-08-13 20:55:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 20:58:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:01:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:04:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:04:31][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:04:31][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:04:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:04:47][INFO] Finished streaming response
[2025-08-13 21:07:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:10:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:13:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:16:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:19:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:22:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:25:38][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:25:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:25:54][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:28:26][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:28:26][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:28:26][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:28:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:28:56][INFO] Finished streaming response
[2025-08-13 21:29:49][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:29:49][INFO][LM STUDIO SERVER] Running chat completion on conversation with 3 messages.
[2025-08-13 21:29:49][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:30:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:30:22][INFO][LM STUDIO SERVER] Running chat completion on conversation with 4 messages.
[2025-08-13 21:30:22][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:30:22][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:30:22][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:30:22][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:31:39][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:31:39][INFO][LM STUDIO SERVER] Running chat completion on conversation with 5 messages.
[2025-08-13 21:31:39][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:31:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:31:45][INFO] Finished streaming response
[2025-08-13 21:32:15][INFO] Finished streaming response
[2025-08-13 21:32:47][INFO] Finished streaming response
[2025-08-13 21:34:28][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:34:28][INFO][LM STUDIO SERVER] Running chat completion on conversation with 6 messages.
[2025-08-13 21:34:28][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:34:28][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:34:28][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:34:28][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:34:28][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:34:28][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:34:28][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:34:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:35:20][INFO] Finished streaming response
[2025-08-13 21:36:17][INFO] Finished streaming response
[2025-08-13 21:36:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:36:36][INFO][LM STUDIO SERVER] Running chat completion on conversation with 7 messages.
[2025-08-13 21:36:36][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:36:55][INFO] Finished streaming response
[2025-08-13 21:37:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:38:14][INFO] Finished streaming response
[2025-08-13 21:39:25][INFO] Finished streaming response
[2025-08-13 21:40:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:43:41][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:43:41][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:43:41][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:43:41][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:43:41][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:43:41][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:43:41][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:43:41][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:43:41][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:43:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:44:11][INFO] Finished streaming response
[2025-08-13 21:44:50][INFO] Finished streaming response
[2025-08-13 21:45:31][INFO] Finished streaming response
[2025-08-13 21:46:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:49:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:52:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:55:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:56:56][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:56:56][INFO][JIT] Requested model (qwen/qwen3-coder-30b) is not loaded. Loading "qwen/qwen3-coder-30b" now...
[2025-08-13 21:57:06][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 21:57:06][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 21:57:12][INFO] Finished streaming response
[2025-08-13 21:58:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 262144,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:58:55][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 262144,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 21:59:03][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 262144,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:01:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 262144,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:02:34][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 262144,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:02:34][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 262144,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:02:34][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 262144,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:02:34][INFO][JIT] Requested model (qwen/qwen3-32b) is not loaded. Loading "qwen/qwen3-32b" now...
[2025-08-13 22:02:43][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:02:43][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:03:09][INFO] Finished streaming response
[2025-08-13 22:04:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:07:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:10:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:13:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:15:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:15:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:15:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:15:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:15:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:15:31][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:15:31][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:15:57][INFO] Finished streaming response
[2025-08-13 22:16:38][INFO] Finished streaming response
[2025-08-13 22:16:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:17:22][INFO] Finished streaming response
[2025-08-13 22:18:01][INFO] Finished streaming response
[2025-08-13 22:18:03][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:18:03][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:18:03][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:18:03][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:18:03][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:18:03][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Running chat completion on conversation with 1 messages.
[2025-08-13 22:18:03][INFO][LM STUDIO SERVER] Streaming response...
[2025-08-13 22:18:47][INFO] Finished streaming response
[2025-08-13 22:19:41][INFO] Finished streaming response
[2025-08-13 22:19:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:20:13][INFO] Finished streaming response
[2025-08-13 22:21:01][INFO] Finished streaming response
[2025-08-13 22:21:50][INFO] Finished streaming response
[2025-08-13 22:22:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:23:19][INFO] Finished streaming response
[2025-08-13 22:23:57][INFO] Finished streaming response
[2025-08-13 22:24:40][INFO] Finished streaming response
[2025-08-13 22:25:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:28:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:31:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:34:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:37:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:40:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:43:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:46:14][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:46:42][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:49:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:50:52][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:51:36][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:52:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:53:05][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:55:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 22:58:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:01:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:04:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:07:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:10:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:13:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:16:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:16:53][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:17:34][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:19:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:22:43][INFO] Returning {
  "data": [
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "loaded",
      "max_context_length": 40960,
      "loaded_context_length": 4096,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:24:40][INFO] Unloading model qwen/qwen3-32b due to TTL expiration.
[2025-08-13 23:25:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:28:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:31:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:34:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:35:14][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:37:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:40:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:41:53][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:43:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:44:28][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:45:06][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:46:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:49:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:52:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:55:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
[2025-08-13 23:58:43][INFO] Returning {
  "data": [
    {
      "id": "openai/gpt-oss-20b",
      "object": "model",
      "type": "llm",
      "publisher": "openai",
      "arch": "gpt-oss",
      "compatibility_type": "gguf",
      "quantization": "MXFP4",
      "state": "not-loaded",
      "max_context_length": 131072,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-nomic-embed-text-v1.5",
      "object": "model",
      "type": "embeddings",
      "publisher": "nomic-ai",
      "arch": "nomic-bert",
      "compatibility_type": "gguf",
      "quantization": "Q4_K_M",
      "state": "not-loaded",
      "max_context_length": 2048
    },
    {
      "id": "qwen/qwen3-coder-30b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3_moe",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 262144,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "text-embedding-qwen3-embedding-0.6b",
      "object": "model",
      "type": "embeddings",
      "publisher": "Qwen",
      "arch": "qwen3",
      "compatibility_type": "gguf",
      "quantization": "Q8_0",
      "state": "not-loaded",
      "max_context_length": 32768,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "qwen/qwen3-32b",
      "object": "model",
      "type": "llm",
      "publisher": "qwen",
      "arch": "qwen3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 40960,
      "capabilities": [
        "tool_use"
      ]
    },
    {
      "id": "google/gemma-3-27b",
      "object": "model",
      "type": "vlm",
      "publisher": "google",
      "arch": "gemma3",
      "compatibility_type": "mlx",
      "quantization": "4bit",
      "state": "not-loaded",
      "max_context_length": 131072
    }
  ],
  "object": "list"
}
